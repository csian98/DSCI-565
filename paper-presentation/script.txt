[9]
The model presented in the paper is shown in the figured above.
Its input are three cartesian coordinates x, y, and z. While it's possible to include additional features.
But in here we only include the coordinate information

Point Cloud data passes through a model called PointNet, and returns classification results and Part Segmentation or Semantic Segmentation results.

[10]
Before looking at the entire network, let's revisit the features of the Point Cloud that we previously highlighted and see how PointNet represents them.

The unordered of the data requires that the same results be achieved for N! permutations, which change the order of the data.
This will be expressed in the network using the Symmetry Function.

Futhermore, segmentation must be able to store information about local and global features for each data points.
This will be achieved using a method called Local and Global Information Aggregation.
This is simply a method of concatenating and using Local features and Global features.

Finally, we will achieve invariance with the results for a specific transformation.
This will be achieved using the Joing Alignment Network, which generates a transformation matrix

[11]
The entire network has the following structure.
The network above is the classification network, and the below is the Segmentation network.
I will explain it by following the input of the network.

[12]
The first is the Feature Transform layer.
Inside it, there is a network called T-Net, which generates a 3x3 matrix for the input data.
It then multiplies the input by the 3x3 matrix and outputs the reesult.
T-Net finds a affine transformation matrix, and uses the reguration here to make the transformation matrix is orthogonal, allowing it to represent affine transformation matrices such as rotations and reflections.

[13]
The following layer is a shared weight MLP.
It is similar to a 1x1 convolutional layer.
It can be expressed as an equation below, and is still pairwise independent.

[14]
Next is the MaxPooling layer,
Previously, each row of the output still contained information about each point.
Now, we need to extract global features using an symmetry function.
In PointNet, this is done using the MaxPooling layer.

Due to time constraints, I've omitted a simple proof, but networks using maxpooling also enable universal approximation and achieve greater stability.
I'll explain this later, if we have time or you guys ask questions.

[15]
We used maxpooling to extract global features representing all points.
However, part segmentation/semantic segmentation still requires local features for each points.
PointNet simply concatenates two features.

[Sup1]
We learned that the multilayer peceptron structure can be a universal function.
The author claims that PointNet is also a universal approximation.
The result of PointNet can be expressed as follows.

When \chi is a set of sets of 3D points, and there is a continuous function f,
if the result of f(S) and PointNet can be the same for all sets of points,
we can call PointNet a Universal Approximation.

[Sup2]
When the interval of normalized points is divided into k, we can assume a continuous function pi that has the value 1 only when the point is included in the interval.

When h(x) is expressed as a function that has 1 only in the interval C_j that includes x, the result u(S) for set of points that went through maxpooling become a function that has alpha only when it has a point include in C_j.

In other words the value of k is sufficiently large, there exists a function gamma that can approximate any permutation invariance function.

[Sup3]
From the previous proof, we can see that the bottleneck is k.
For a set of points S, at most k points contribute to the result of max pooling.
Let N_s be the upper bound set.
If we input any arbitrary T, which is a supset of C_S and a subset of N_S, we can see that the same output is always obtained, which leads to a stable result.
